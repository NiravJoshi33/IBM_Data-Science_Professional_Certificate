{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Science Methodology Overview\n",
    "- Business Understanding\n",
    "- Analytic Approach\n",
    "- Data Requirements\n",
    "- Data Collection\n",
    "- Data Understanding\n",
    "- Data Preparation\n",
    "- Modeling\n",
    "- Evaluation\n",
    "- Deployment\n",
    "- Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Understanding\n",
    "Seek clarification. What is the goal of the person with the problem?\\\n",
    "Figure out the objectives that are in line with the goals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analytic Approach\n",
    "How can you use the data to asnwer the question?\\\n",
    "If question is the determine probabilities of an action - Use predictive model\\\n",
    "If question is to show relationships - Use descriptive model\\\n",
    "If question required Yes or No answer - Use classification model\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Requirements\n",
    "Understanding that what kind of data will be required for the given problem, what will be the sources etc. It's like understanding what ingredients will be required to make a recipe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection\n",
    "In this stage, it is evaluated whether all the ingredients required for the recipe are available or not. If because of some unavoidable reason not, then data requirements are revised and collected data is evaluated again. \n",
    "\n",
    "Techniques such as descriptive, statistics and visualization is used to assess the quality, contents and initial insights about the data. \n",
    "\n",
    "Gaps will be identified in the data and plans to either fill or substitute will be made. \n",
    "\n",
    "### Data Integration\n",
    "Collecting and merging data from different sources\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding\n",
    "Stage where data scientists discuss various ways to manage data effectively, including automating certain processes in the database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descriptive Statistics\n",
    "- Univariate Statistics - statistics to describe data with only one attribute\n",
    "- Pairwise Correlations - identifying correlated features\n",
    "- Histogram - graph used to represent frequency distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "Process of organizing and formatting the data to meet requirements of the modeling technique. much like cleansing data.\n",
    "\n",
    "Most time consuming phase - takes 70-90% of total time\n",
    "\n",
    "It is important to provide sufficient time in this stage. \n",
    "\n",
    "#### Feature Engineering\n",
    "    Part of Data Preparation\n",
    "    process of using domain knowledge of the data to create features that make the machine learning algorithms work. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Modeling to Evaluation\n",
    "### Modeling\n",
    "Focuses on developing models that are either predictive or descriptive. \n",
    "\n",
    "Stage where the cook has a chance to taste(sample) the sauce and decide whether it is bang on! or something needs to be changed. \n",
    "\n",
    "Sometimes it is important to adjust the weight of the parameters, in our example of C Heart Failure Readdmission study, cost of misclassifying case as yes when it is not a readdmission or misclassifying it as no (False Positive) when it is actually readdmission, In case of the first scenario (False Negative), the effort added to prevent the readdmission is waster but in case of later scenario, the cost is much larger which is cost of readdmission, care taken after readdmission and patient trauma. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "Modeling and Evaluation goes hand in hand. It is performed during model development and before the deployment. \n",
    "\n",
    "The model is evaluated two ways:\n",
    "1. Diagnostic Measures\n",
    "2. Statistical Significance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Deployment to Feedback\n",
    "### Deployment\n",
    "Once necessary tuning is done and the data scientists are confident on the model, the model is deployed and put to the ultimate test. \n",
    "\n",
    "### Feedback\n",
    "Plan for the feedback process\n",
    "    - Define Review Process\n",
    "        - Model will be applied to the new data and the actual results of the data will be monitored.\n",
    "        - Predicted results will be compared with the actual results. \n",
    "    - Refine model\n",
    "        - After the feedback is gathered for sometime after the intial deployment, based on this feedback and knowledge gained, model will be refined. \n",
    "        - Initially unavailable data should be available by this time, so that can also be implemented into the model. \n",
    "    - Review and Refine Intervention Actions\n",
    "        - These are the actions performed based on the predictive results obtained from the model. \n",
    "    - Redeployment of the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRISP-DM\n",
    "Cross-Industry Standard Data Process for Data Mining\n",
    "\n",
    "A structured approach to guide data-driven decision making\n",
    "\n",
    "**Stages of CRISP-DM**\n",
    "- B"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
